{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6JC45gEUY_kr"
      },
      "outputs": [],
      "source": [
        "!pip install -q transformers sentence-transformers faiss-cpu accelerate"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import transformers\n",
        "import sentence_transformers\n",
        "import faiss\n",
        "\n",
        "print(\"All libraries installed successfully âœ…\")\n"
      ],
      "metadata": {
        "id": "dbDmZDK-aLWH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "\n",
        "model_name = \"TinyLlama/TinyLlama-1.1B-Chat-v1.0\"\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_name,\n",
        "    device_map=\"auto\"\n",
        ")\n",
        "\n",
        "print(\"LLM loaded successfully âœ…\")\n"
      ],
      "metadata": {
        "id": "vu8sasf-hVJi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"Explain RAG in one sentence.\"\n",
        "\n",
        "inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
        "outputs = model.generate(\n",
        "    **inputs,\n",
        "    max_new_tokens=50\n",
        ")\n",
        "\n",
        "print(tokenizer.decode(outputs[0], skip_special_tokens=True))"
      ],
      "metadata": {
        "id": "4gr3Sn_Gh2cx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "os.listdir(\"/content\")"
      ],
      "metadata": {
        "id": "jXH7BBH7iQIq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q pypdf"
      ],
      "metadata": {
        "id": "0rYkLUXSjKNW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pypdf import PdfReader\n",
        "\n",
        "reader = PdfReader(\"/content/swiggy_con_call.pdf\")\n",
        "\n",
        "text = \"\"\n",
        "for page in reader.pages:\n",
        "    text += page.extract_text()\n",
        "\n",
        "print(text[:1000])  # preview first 1000 characters"
      ],
      "metadata": {
        "id": "WiixmVVLjN-C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def chunk_text(text, chunk_size=500, overlap=100):\n",
        "    chunks = []\n",
        "    start = 0\n",
        "\n",
        "    while start < len(text):\n",
        "        end = start + chunk_size\n",
        "        chunk = text[start:end]\n",
        "        chunks.append(chunk)\n",
        "        start = end - overlap\n",
        "\n",
        "    return chunks"
      ],
      "metadata": {
        "id": "eQe0NWfnjczn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chunks = chunk_text(text)\n",
        "\n",
        "print(f\"Total chunks created: {len(chunks)}\")\n",
        "print(\"\\n--- Sample chunk ---\\n\")\n",
        "print(chunks[0][:800])\n"
      ],
      "metadata": {
        "id": "143t2FY6kZQ0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "embedding_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
        "\n",
        "print(\"Embedding model loaded âœ…\")"
      ],
      "metadata": {
        "id": "ae7XuRjOkbZ0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chunk_embeddings = embedding_model.encode(chunks, show_progress_bar=True)\n",
        "\n",
        "print(f\"Embedding shape: {chunk_embeddings.shape}\")"
      ],
      "metadata": {
        "id": "X8pDohmMljJt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import faiss\n",
        "import numpy as np\n",
        "\n",
        "dimension = chunk_embeddings.shape[1]\n",
        "\n",
        "index = faiss.IndexFlatL2(dimension)\n",
        "index.add(np.array(chunk_embeddings))\n",
        "\n",
        "print(f\"FAISS index created with {index.ntotal} vectors âœ…\")\n"
      ],
      "metadata": {
        "id": "zqm4JLzonE94"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ---- Document Scope Configuration ----\n",
        "DOCUMENT_SCOPE = {\n",
        "    \"company\": \"Swiggy\",\n",
        "    \"blocked_entities\": [\"zomato\", \"ubereats\", \"blinkit\"]\n",
        "}"
      ],
      "metadata": {
        "id": "M980sv1qq99f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def retrieve_chunks_with_scores(query, k=3):\n",
        "    query_embedding = embedding_model.encode([query])\n",
        "    distances, indices = index.search(query_embedding, k)\n",
        "    return distances[0], [chunks[i] for i in indices[0]]"
      ],
      "metadata": {
        "id": "XCK2zsTMnT63"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"What did Swiggy say about profitability?\"\n",
        "results = retrieve_chunks(query)\n",
        "\n",
        "print(\"\\n--- Retrieved Chunks ---\\n\")\n",
        "for i, chunk in enumerate(results):\n",
        "    print(f\"Chunk {i+1}:\\n{chunk[:500]}\\n\")\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "ijr3T1yinW0L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(chunk)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "tmKjP71LnZRJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_prompt(context_chunks, question):\n",
        "    context = \"\\n\\n\".join(context_chunks)\n",
        "\n",
        "    prompt = f\"\"\"\n",
        "You are an analyst assistant.\n",
        "Answer the question ONLY using the context below.\n",
        "If the answer is not present, say \"Not mentioned in the document\".\n",
        "\n",
        "Context:\n",
        "{context}\n",
        "\n",
        "Question:\n",
        "{question}\n",
        "\n",
        "Answer:\n",
        "\"\"\"\n",
        "    return prompt"
      ],
      "metadata": {
        "id": "47yf_83Xns8F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def rag_answer(question, k=3, relevance_threshold=1.2):\n",
        "\n",
        "    q_lower = question.lower()\n",
        "\n",
        "    # ðŸš¨ HARD DOCUMENT SCOPE CHECK\n",
        "    for entity in DOCUMENT_SCOPE[\"blocked_entities\"]:\n",
        "        if entity in q_lower:\n",
        "            return (\n",
        "                f\"This document is about {DOCUMENT_SCOPE['company']}. \"\n",
        "                f\"It does not contain information about {entity.capitalize()}.\"\n",
        "            )\n",
        "\n",
        "    # ðŸ” Semantic retrieval\n",
        "    distances, context_chunks = retrieve_chunks_with_scores(question, k)\n",
        "\n",
        "    # ðŸš¨ Retrieval confidence gate\n",
        "    if min(distances) > relevance_threshold:\n",
        "        return \"This document does not contain information related to this question.\"\n",
        "\n",
        "    context = \"\\n\\n\".join(context_chunks)\n",
        "\n",
        "    prompt = f\"\"\"\n",
        "You are a document-grounded assistant.\n",
        "\n",
        "STRICT RULES:\n",
        "- Use ONLY the context below\n",
        "- Do NOT use external knowledge\n",
        "- Do NOT infer or guess\n",
        "- If the answer is not explicitly present, say:\n",
        "  \"This document does not contain information related to this question.\"\n",
        "\n",
        "Context:\n",
        "{context}\n",
        "\n",
        "Question:\n",
        "{question}\n",
        "\n",
        "Answer:\n",
        "\"\"\"\n",
        "\n",
        "    inputs = tokenizer(\n",
        "        prompt,\n",
        "        return_tensors=\"pt\",\n",
        "        truncation=True,\n",
        "        max_length=2048\n",
        "    )\n",
        "\n",
        "    outputs = model.generate(\n",
        "        **inputs,\n",
        "        max_new_tokens=120,\n",
        "        temperature=0.1\n",
        "    )\n",
        "\n",
        "    return tokenizer.decode(outputs[0], skip_special_tokens=True)\n"
      ],
      "metadata": {
        "id": "32tXBRBwn8g1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"What did Swiggy management say about profitability and margins?\"\n",
        "answer = rag_answer(question)\n",
        "\n",
        "print(answer)\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "6-T-YwploBj-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"Give a 200 word summary of Swiggy's food delivery business.\"\n",
        "\n",
        "answer = rag_answer(question, k=5)\n",
        "\n",
        "print(answer)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "sDp7v7vUoEUe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "answer = rag_answer(\n",
        "    \"Give a 200 word summary of Swiggy's food delivery business.\",\n",
        "    k=5\n",
        ")\n",
        "\n",
        "# Clean and print one line below the other\n",
        "sentences = answer.replace(\"\\n\", \" \").split(\".\")\n",
        "\n",
        "print(\"\\n--- Clean Line-by-Line Output ---\\n\")\n",
        "for s in sentences:\n",
        "    s = s.strip()\n",
        "    if len(s) > 20:  # avoid very small junk lines\n",
        "        print(\"- \" + s + \".\")"
      ],
      "metadata": {
        "collapsed": true,
        "id": "RTMJSBTlo0W4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q gradio"
      ],
      "metadata": {
        "id": "i29I8eJUpjow"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def rag_ui(question):\n",
        "    if question.strip() == \"\":\n",
        "        return \"Please enter a question.\"\n",
        "\n",
        "    answer = rag_answer(question, k=5)\n",
        "\n",
        "    # Clean formatting for UI\n",
        "    sentences = answer.replace(\"\\n\", \" \").split(\".\")\n",
        "    formatted = \"\"\n",
        "    for s in sentences:\n",
        "        s = s.strip()\n",
        "        if len(s) > 20:\n",
        "            formatted += \"â€¢ \" + s + \".\\n\\n\"\n",
        "\n",
        "    return formatted"
      ],
      "metadata": {
        "id": "1UE5dbNTqdo-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "\n",
        "ui = gr.Interface(\n",
        "    fn=rag_ui,\n",
        "    inputs=gr.Textbox(\n",
        "        lines=3,\n",
        "        placeholder=\"Ask about Swiggy food delivery business, profitability, growth...\"\n",
        "    ),\n",
        "    outputs=gr.Textbox(\n",
        "        lines=15,\n",
        "        label=\"RAG Answer\"\n",
        "    ),\n",
        "    title=\"ðŸ“Š Swiggy Earnings Call RAG Assistant\",\n",
        "    description=\"Ask questions grounded ONLY in the Swiggy earnings call document.\"\n",
        ")\n",
        "\n",
        "ui.launch()\n"
      ],
      "metadata": {
        "id": "3p-TcQCUqkX2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E6SX8a6htH0c",
        "outputId": "5e17af72-ecb5-49f9-d90a-f8f22b4fa8ae"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "data  notebooks  sample_data  src  swiggy_con_call.pdf\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls notebooks\n",
        "!ls data\n",
        "!sed -n '1,20p' README.md"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6NPQfww-tLyz",
        "outputId": "17fed6ab-6e66-40d8-b3c6-8da205067e0a"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sed: can't read README.md: No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git init"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aNRHnMofvuzt",
        "outputId": "5def081d-f522-4d63-cdc9-afb4909742b7"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33mhint: Using 'master' as the name for the initial branch. This default branch name\u001b[m\n",
            "\u001b[33mhint: is subject to change. To configure the initial branch name to use in all\u001b[m\n",
            "\u001b[33mhint: of your new repositories, which will suppress this warning, call:\u001b[m\n",
            "\u001b[33mhint: \u001b[m\n",
            "\u001b[33mhint: \tgit config --global init.defaultBranch <name>\u001b[m\n",
            "\u001b[33mhint: \u001b[m\n",
            "\u001b[33mhint: Names commonly chosen instead of 'master' are 'main', 'trunk' and\u001b[m\n",
            "\u001b[33mhint: 'development'. The just-created branch can be renamed via this command:\u001b[m\n",
            "\u001b[33mhint: \u001b[m\n",
            "\u001b[33mhint: \tgit branch -m <name>\u001b[m\n",
            "Initialized empty Git repository in /content/.git/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git commit -m \"Initial commit: end-to-end RAG system with hallucination guardrails\"\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_aXqRFvnwAM7",
        "outputId": "1e71cdcb-68d7-49ed-ddd7-4d415f06a1f2"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Author identity unknown\n",
            "\n",
            "*** Please tell me who you are.\n",
            "\n",
            "Run\n",
            "\n",
            "  git config --global user.email \"you@example.com\"\n",
            "  git config --global user.name \"Your Name\"\n",
            "\n",
            "to set your account's default identity.\n",
            "Omit --global to set the identity only in this repository.\n",
            "\n",
            "fatal: unable to auto-detect email address (got 'root@06990d43c785.(none)')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Tools used\n",
        "#Read pdf: pypdf\n",
        "#Vector database: FAISS\n",
        "#Chuncking: RecursiveCharacterTextSplitter\n",
        "#Ebidding:\n",
        "Tool used: sentence-transformers\n",
        "Model: all-MiniLM-L6-v2\n",
        "#Query Embedding & Retrieval: sentence-transformers + FAISS\n",
        "#UI layer: Gradio\n"
      ],
      "metadata": {
        "id": "rB_gdPY0qnN4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aG98fG5AoNOg"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}